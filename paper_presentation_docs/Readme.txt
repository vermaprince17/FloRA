All finetuning related codes are here - https://github.com/vermaprince17/FloRA ; 
all corrosponding ckpts and finetuning experiments logged here - https://wandb.ai/crazy_nlp_boiz/FloRA

The entire project (eval) - https://github.com/punith300i/nlp-vlm-project 
Run `eval_script (VQAv2).ipynb` as an example notebook to evaluate pre-trained baseline Open-Flamingo models on the VQAv2 dataset. Note: intended for Google Colab

Use the `evaluate.py` script to run customizable evalution on the VQAv2 dataset for MMGPT models with fine-tuned checkpoints for Open-Flamingo weights and by substituting different languagte and vision encoders.
Execute the `mmgpt_VQAv2_eval.ipynb` notebook in Google Colab as an example of running inference evaluation on the VQAv2 dataset with fine-tuned OpenFlamingo checkpoints, customized hyperparameters, and substituting different vision or language models.
