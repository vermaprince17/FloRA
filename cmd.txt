python mmgpt/train/instruction_finetune.py --lm_path openlm-research/open_llama_3B_V2 --tokenizer_path openlm-research/open_llama_3B_V2 --pretrained_path checkpoints/OpenFlamingo-9B/checkpoint.pt --run_name train-my-gpt4 --learning_rate 1e-5 --lr_scheduler cosine --batch_size 4 --num_epochs 2 --logging_steps 2 --tuning_config configs/lora_config.py --dataset_config configs/dataset_config.py --report_to_wandb
